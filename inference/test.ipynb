{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from polygon import RESTClient\n",
    "from datetime import datetime,timezone\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(\"../guidelight-api/.env\")\n",
    "token = os.getenv(\"POLYGON_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = RESTClient(api_key=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AAPL\"\n",
    "\n",
    "# List Aggregates (Bars)\n",
    "aggs = []\n",
    "for a in client.list_aggs(ticker=ticker, multiplier=1, timespan=\"minute\", from_=\"2019-01-01\", to=\"2023-12-30\", limit=50000):\n",
    "    aggs.append(a)\n",
    "\n",
    "print(len(aggs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unix millisecond timestamp to datetime\n",
    "# from pytz import timezone\n",
    "\n",
    "# Convert timestamp to datetime in UTC timezone\n",
    "def ts_to_dt(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp/1000, tz=timezone.utc)\n",
    "\n",
    "timestamps = np.vectorize(ts_to_dt)\n",
    "\n",
    "# Example usage\n",
    "a = np.array([a.timestamp for a in aggs])\n",
    "times = timestamps(a)\n",
    "aapl_aggs = pd.DataFrame({\"day\": [time.strftime(\"%Y-%m-%d\") for time in times],\n",
    "                            \"timestamp\": [time.strftime(\"%Y-%m-%d, %H:%M\") for time in times],\n",
    "                           \"close\": [a.close for a in aggs], \n",
    "                           \"volume\": [a.volume for a in aggs],\n",
    "                           \"low\": [a.low for a in aggs],\n",
    "                           \"high\": [a.high for a in aggs]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heston_param import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_aggs.groupby(\"day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_aggs =  [aapl_aggs.groupby('day').get_group(x) for x in aapl_aggs['day'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_voilatilities = torch.empty(len(daily_aggs))\n",
    "for i, day in enumerate(daily_aggs):\n",
    "\thist_voilatilities[i] = estimate_historical_volatility(day['close'].values)\n",
    "\n",
    "# calculate the historical volatility for each day\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(hist_voilatilities, open(\"hist_voilatilities.pkl\", \"wb\"))\n",
    "pickle.dump(daily_aggs, open(\"daily_aggs.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_voilatilities = pickle.load(open(\"hist_voilatilities.pkl\", \"rb\"))\n",
    "daily_aggs = pickle.load(open(\"daily_aggs.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            day          timestamp    close   volume      low     high\n",
      "0    2019-04-08  2019-04-08, 08:11  49.0675   2308.0  49.0675  49.0875\n",
      "1    2019-04-08  2019-04-08, 08:13  49.0875    744.0  49.0875  49.0875\n",
      "2    2019-04-08  2019-04-08, 08:26  49.0875    400.0  49.0875  49.0875\n",
      "3    2019-04-08  2019-04-08, 08:34  49.0675   1200.0  49.0675  49.0750\n",
      "4    2019-04-08  2019-04-08, 08:40  49.1225    688.0  49.1225  49.1225\n",
      "..          ...                ...      ...      ...      ...      ...\n",
      "609  2019-04-08  2019-04-08, 23:50  50.1125   8240.0  50.1125  50.1450\n",
      "610  2019-04-08  2019-04-08, 23:55  50.1325   1444.0  50.1325  50.1350\n",
      "611  2019-04-08  2019-04-08, 23:56  50.1500   8200.0  50.1325  50.1500\n",
      "612  2019-04-08  2019-04-08, 23:57  50.1500  12600.0  50.1500  50.1500\n",
      "613  2019-04-08  2019-04-08, 23:59  50.1450   4360.0  50.1425  50.1450\n",
      "\n",
      "[614 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(calibrate_daily_parameters(hist_voilatilities[0], 0.1, daily_aggs[0][\"close\"].values, 0.0237, 390, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guidelight-Popvxsqg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
