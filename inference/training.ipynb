{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from polygon import RESTClient\n",
    "from datetime import datetime, timedelta\n",
    "import pandas_market_calendars as mcal\n",
    "import polygon\n",
    "import os, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_diff = lambda date1, date2 : (datetime.strptime(date1, '%Y-%m-%d') - datetime.strptime(date2, '%Y-%m-%d')).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"/Users/brad/mlprojects/guidelight/guidelight-api/.env\")\n",
    "token = os.getenv(\"POLYGON_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = RESTClient(api_key=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(data, open(\"options_data/AAPL-2023-03-27.pkl\", \"wb\"))\n",
    "if not os.path.exists(\"all_contracts.pkl\"):\n",
    "\treqs = client.list_options_contracts(\"AAPL\",as_of=\"2024-04-16\", expired=True, expiration_date_gt=\"2023-04-16\")\n",
    "\tall_contracts = list(reqs)\n",
    "\tpickle.dump(all_contracts, open(\"all_contracts.pkl\", \"wb\"))\n",
    "else:\n",
    "\tall_contracts = pickle.load(open(\"all_contracts.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6164"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_contracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data = {\n",
    "#     ('AAPL_2207C00500000', '2023-07-21'): [\n",
    "#         {'trading_date': '2023-07-01', 'strike': 500, 'open': 15.5, 'high': 16.0, 'low': 15.0, 'close': 15.75, 'volume': 300},\n",
    "#         {'trading_date': '2023-07-02', 'strike': 500, 'open': 15.6, 'high': 17.0, 'low': 15.2, 'close': 16.50, 'volume': 350}\n",
    "#     ],\n",
    "#     ('MSFT_2207P00250000', '2023-07-21'): [\n",
    "#         {'trading_date': '2023-07-01', 'strike': 250, 'open': 8.5, 'high': 9.0, 'low': 8.0, 'close': 8.75, 'volume': 200},\n",
    "#         {'trading_date': '2023-07-02', 'strike': 250, 'open': 8.6, 'high': 10.0, 'low': 8.1, 'close': 9.75, 'volume': 250}\n",
    "#     ]\n",
    "# }\n",
    "if not os.path.exists(\"data.pkl\"):\n",
    "    indices = [(contract.ticker, contract.expiration_date, contract.strike_price) for contract in all_contracts]\n",
    "    data = {}\n",
    "    for index in indices:\n",
    "        ticker, expiration_date, strike_price = index\n",
    "        current_date = datetime.strptime(expiration_date, \"%Y-%m-%d\")\n",
    "        past_date = current_date - timedelta(days=14)\n",
    "\n",
    "        # get key value data for each agg\n",
    "\n",
    "        a = [vars(agg) for agg in client.get_aggs(ticker, 1, 'day', past_date, current_date)]\n",
    "        data[index] = a\n",
    "\n",
    "\n",
    "    pickle.dump(data, open(\"data.pkl\", \"wb\"))\n",
    "\n",
    "else:\n",
    "    data = pickle.load(open(\"data.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset = pd.DataFrame(columns=['Weight', 'price', 'maturity', 'S'])\n",
    "# dataset['Weight'] = df['volume'] / df.volume.sum()\n",
    "# dataset['price']  = df['price']\n",
    "# dataset['maturity'] = df['maturity']\n",
    "# dataset['S']        = df['strike_price']\n",
    "# dataset['time_from_last_trade'] = -df['days since last trade']\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data while preserving the option ticker and expiration date\n",
    "flattened_data = []\n",
    "for (ticker, expiration, strike_price), entries in data.items():\n",
    "    for entry in entries:\n",
    "        entry.update({\n",
    "            \"ticker\": ticker,\n",
    "            \"expiration_date\": expiration,\n",
    "            \"strike_price\": strike_price\n",
    "        })\n",
    "        flattened_data.append(entry)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Set a MultiIndex using the ticker, expiration date, and trading date\n",
    "df.set_index(['ticker', \"strike_price\", 'expiration_date'], inplace=True)\n",
    "\n",
    "# get by ticker\n",
    "# 1681099200000\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms').dt.strftime(\"%Y-%m-%d\")\n",
    "# df.index = df.index.set_levels(pd.to_datetime(df.index.get_level_values('timestamp'), unit='ms').strftime('%Y-%m-%d %H:%M:%S'), level='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"options_data-aapl.csv\", index_label=['ticker', \"strike_price\", 'expiration_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('options_data-aapl.csv', index_col=[0, 1, 2])\n",
    "# get only the tickers traded on 2023-04-10\n",
    "# df2.groupby('timestamp').filter(lambda x: x['timestamp']== '2023-04-10')\n",
    "# get the level values\n",
    "\n",
    "agg_series= df.loc[('O:AAPL230421C00050000', slice(None), slice(None))]\n",
    "target_timestamp = '2023-04-19'\n",
    "\n",
    "# Create a boolean mask for rows where the timestamp matches the target\n",
    "i = np.where(agg_series['timestamp'].values == target_timestamp)[0][0]\n",
    "# agg_series\n",
    "diff = datetime_diff(agg_series['timestamp'].iloc[i], agg_series['timestamp'].iloc[i-1])\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_option_data(underlying_ticker:str, date:str):\n",
    "\t# client = RESTClient(api_key=token)\n",
    "\tdf = pd.read_csv(f'options_data-{underlying_ticker}.csv', index_col=[0, 1, 2])\n",
    "\toption_contracts = df2.loc[df2['timestamp'] == date]\n",
    "\tcolnames = [\"ticker\", \"maturity\", \"Weight\", 'volume', 'price', 'days since last trade', 'S']\n",
    "\tdf = pd.DataFrame(columns=colnames)\n",
    "\n",
    "\tfor ticker in option_contracts.get_level_values(0).unique():\n",
    "\t\tagg_series= df.loc[(ticker, slice(None), slice(None))]\n",
    "\t\t\n",
    "\t\ti = np.where(agg_series['timestamp'].values == date)[0][0]\n",
    "\t# agg_series\n",
    "\t\tdiff = datetime_diff(agg_series['timestamp'].iloc[i], agg_series['timestamp'].iloc[i-1])\n",
    "\n",
    "\t\ta = pd.DataFrame([contract.__dict__.values()], columns=cols)\n",
    "\t\ta['maturity'] = (expiration_time - today).days / 365\n",
    "\t\ta['volume'] = option_contracts[i][\"volume\"]\n",
    "\t\ta['price'] = option_contracts[i][\"vwap\"]\n",
    "\t\ta['days since last trade'] = diff\n",
    "\t\tdf = pd.concat([df, a])\n",
    "\n",
    "\t\n",
    "\tdf.to_csv( os.path.join(os.getcwd(), f\"options_data/{underlying_ticker}-{date}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "def worker(date, underlying_ticker, contract_type):\n",
    "    load_dotenv(\"/Users/brad/mlprojects/guidelight/guidelight-api/.env\")\n",
    "    token = os.getenv(\"POLYGON_TOKEN\")\n",
    "    return daily_option_data(underlying_ticker, date, token, contract_type)\n",
    "\n",
    "\n",
    "def process_multiple_days(underlying_ticker, start_date, end_date, contract_type=\"put\"):\n",
    "    # Generate list of dates\n",
    "    dates = mcal.get_calendar(\"NYSE\").valid_days(start_date=start_date, end_date=end_date)\n",
    "    \n",
    "    # Define a helper to wrap your existing function for use with starmap\n",
    "    \n",
    "\n",
    "    # Setup multiprocessing pool\n",
    "    with Pool() as pool:\n",
    "        pool.starmap(worker, [(date, underlying_ticker, contract_type) for date in dates])\n",
    "\n",
    "    print(\"Data processing complete for all specified dates.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "process_multiple_days('AAPL', '2023-04-17', '2024-04-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_rates = pd.read_csv(\"five-year-rates.csv\")\n",
    "yield_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AAPL\"\n",
    "\n",
    "# List Aggregates (Bars)\n",
    "aggs = []\n",
    "for a in client.list_aggs(ticker=ticker, multiplier=1, timespan=\"minute\", from_=\"2022-01-01\", to=\"2023-12-30\", limit=50000, options=T):\n",
    "    aggs.append(a)\n",
    "\n",
    "print(len(aggs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unix millisecond timestamp to datetime\n",
    "# from pytz import timezone\n",
    "\n",
    "# Convert timestamp to datetime in UTC timezone\n",
    "def ts_to_dt(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp/1000, tz=timezone.utc)\n",
    "\n",
    "timestamps = np.vectorize(ts_to_dt)\n",
    "\n",
    "# Example usage\n",
    "a = np.array([a.timestamp for a in aggs])\n",
    "times = timestamps(a)\n",
    "aapl_aggs = pd.DataFrame({\"day\": [time.strftime(\"%Y-%m-%d\") for time in times],\n",
    "                            \"timestamp\": [time.strftime(\"%Y-%m-%d, %H:%M\") for time in times],\n",
    "                           \"close\": [a.close for a in aggs], \n",
    "                           \"volume\": [a.volume for a in aggs],\n",
    "                           \"low\": [a.low for a in aggs],\n",
    "                           \"high\": [a.high for a in aggs]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heston_param import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_aggs.groupby(\"day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_aggs =  [aapl_aggs.groupby('day').get_group(x) for x in aapl_aggs['day'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_voilatilities = torch.empty(len(daily_aggs))\n",
    "for i, day in enumerate(daily_aggs):\n",
    "\thist_voilatilities[i] = estimate_historical_volatility(day['close'].values)\n",
    "\n",
    "# calculate the historical volatility for each day\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from heston_param import *\n",
    "hist_voilatilities = pickle.load(open(\"hist_voilatilities.pkl\", \"rb\"))\n",
    "daily_aggs = pickle.load(open(\"daily_aggs.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\ttry:\n",
    "\t\tprint(calibrate_daily_parameters(hist_voilatilities[0], 0.1, daily_aggs[0][\"close\"].values, 0.0237, daily_aggs[0][\"close\"].values.shape[0], 50))\n",
    "\t\tbreak\n",
    "\texcept RuntimeError:\n",
    "\t\tcontinue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_day_calibration(args):\n",
    "\t\ti, hist_volatilities, daily_agg = args\n",
    "\t\twhile True:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tparams = calibrate_daily_parameters(hist_volatilities[i], 0.1, day[\"close\"].values, 0.0237, day[\"close\"].values.shape[0], 300)\n",
    "\t\t\t\t\n",
    "\t\t\t\treturn i, params\n",
    "\t\t\texcept RuntimeError:\n",
    "\t\t\t\tcontinue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(daily_aggs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Monte Carlo:\n",
    "Runtime: 1.15 Hour. Suboptimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_params = np.empty((len(daily_aggs), 5))\n",
    "for i, day in enumerate((daily_aggs[:20])):\n",
    "\twhile True:\n",
    "\t\ttry:\n",
    "\t\t\tdaily_params[i] = calibrate_daily_parameters(hist_voilatilities[i], 0.1, daily_aggs[i][\"close\"].values, 0.0237, daily_aggs[i][\"close\"].values.shape[0], 50)\n",
    "\t\t\tif (i + 1) % 10 == 0:\n",
    "\t\t\t\t\trate =  100 *  np.round((i + 1) /len(daily_params[:20]), 2)\n",
    "\t\t\t\t\tprint(f\"{rate}% completed.\")\n",
    "\t\t\t\n",
    "\t\t\tbreak\n",
    "\t\texcept RuntimeError:\n",
    "\t\t\tcontinue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_worker(args):\n",
    "\tsingle_day_calibration(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_params = pickle.load(open(\"parameters.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime is 1.5 hours\n",
    "daily_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocess import Pool\n",
    "\n",
    "def calibrate_parameters_multiprocessing(daily_aggs, hist_volatilities):\n",
    "    # Prepare arguments for each task\n",
    "    tasks = [(i, hist_volatilities[i], daily_aggs[i]) for i in range(len(daily_aggs))]\n",
    "\n",
    "    # Number of processes, could be set to the number of CPUs or cores\n",
    "    num_processes = 4\n",
    "\n",
    "    # Create a multiprocessing pool and map tasks to worker function\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = pool.map(calibrate_worker, tasks)\n",
    "\n",
    "    # Process results\n",
    "    daily_params = np.empty((len(daily_aggs[:20]), 5))\n",
    "    for index, params in results:\n",
    "        if params is not None:\n",
    "            daily_params[index] = params\n",
    "        else:\n",
    "            print(f\"Calibration failed for index {index}\")\n",
    "\n",
    "    return daily_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate_parameters_multiprocessing(daily_aggs[:20], hist_voilatilities[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@alexander.tsoskounoglou/pricing-options-with-fourier-series-p3-the-heston-model-d157369a217a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heston_char(u, params):\n",
    "    kappa, theta, zeta, rho, v0, r, q, T, S0 = params \n",
    "    t0 = 0.0 ;  q = 0.0\n",
    "    m = np.log(S0) + (r - q)*(T-t0)\n",
    "    D = np.sqrt((rho*zeta*1j*u - kappa)**2 + zeta**2*(1j*u + u**2))\n",
    "    C = (kappa - rho*zeta*1j*u - D) / (kappa - rho*zeta*1j*u + D)\n",
    "    beta = ((kappa - rho*zeta*1j*u - D)*(1-np.exp(-D*(T-t0)))) / (zeta**2*(1-C*np.exp(-D*(T-t0))))\n",
    "    alpha = ((kappa*theta)/(zeta**2))*((kappa - rho*zeta*1j*u - D)*(T-t0) - 2*np.log((1-C*np.exp(-D*(T-t0))/(1-C))))\n",
    "    return np.exp(1j*u*m + alpha + beta*v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sqrt, exp, pi, cos, sin, log, abs\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def Fourier_Heston_Put(S0, K, T, r, \n",
    "                  # Heston Model Paramters\n",
    "                  kappa, # Speed of the mean reversion \n",
    "                  theta, # Long term mean\n",
    "                  rho,   # correlation between 2 random variables\n",
    "                  zeta,  # Volatility of volatility\n",
    "                  v0,    # Initial volatility \n",
    "                  opt_type,\n",
    "                  N = 1_012,\n",
    "                  z = 24\n",
    "                  ):\n",
    "\n",
    "  def heston_char(u): \n",
    "    t0 = 0.0 ;  q = 0.0\n",
    "    m = log(S0) + (r - q)*(T-t0)\n",
    "    D = sqrt((rho*zeta*1j*u - kappa)**2 + zeta**2*(1j*u + u**2))\n",
    "    C = (kappa - rho*zeta*1j*u - D) / (kappa - rho*zeta*1j*u + D)\n",
    "    beta = ((kappa - rho*zeta*1j*u - D)*(1-exp(-D*(T-t0)))) / (zeta**2*(1-C*exp(-D*(T-t0))))\n",
    "    alpha = ((kappa*theta)/(zeta**2))*((kappa - rho*zeta*1j*u - D)*(T-t0) - 2*log((1-C*exp(-D*(T-t0))/(1-C))))\n",
    "    return exp(1j*u*m + alpha + beta*v0)\n",
    "  \n",
    "  # # Parameters for the Function to make sure the approximations are correct.\n",
    "  c1 = log(S0) + r*T - .5*theta*T\n",
    "  c2 = theta/(8*kappa**3)*(-zeta**2*exp(-2*kappa*T) + 4*zeta*exp(-kappa*T)*(zeta-2*kappa*rho) \n",
    "        + 2*kappa*T*(4*kappa**2 + zeta**2 - 4*kappa*zeta*rho) + zeta*(8*kappa*rho - 3*zeta))\n",
    "  a = c1 - z*sqrt(abs(c2))\n",
    "  b = c1 + z*sqrt(abs(c2))\n",
    "  \n",
    "  h       = lambda n : (n*pi) / (b-a) \n",
    "  g_n     = lambda n : (exp(a) - (K/h(n))*sin(h(n)*(a - log(K))) - K*cos(h(n)*(a - log(K)))) / (1 + h(n)**2)\n",
    "  g0      = K*(log(K) - a - 1) + exp(a)\n",
    "  \n",
    "  F = g0 \n",
    "  for n in range(1, N+1):\n",
    "    h_n = h(n)\n",
    "    F += 2*heston_char(h_n) * exp(-1j*a*h_n) * g_n(n)\n",
    "\n",
    "  F = exp(-r*T)/(b-a) * np.real(F)\n",
    "  F = F if opt_type == 'p' else F + S0 - K*exp(-r*T)\n",
    "  return F if F > 0 else 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0      = 100.      # initial asset price\n",
    "K       = 50.       # strike\n",
    "r       = 0.03      # risk free rate\n",
    "T       = 1/365     # time to maturity\n",
    "\n",
    "v0=0.4173 ; kappa=0.4352 ; theta=0.2982 ; zeta=1.3856 ; rho=-0.0304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_vollib_vectorized\n",
    "\n",
    "price = 0.10 ; S = 95 ; K = 100 ; t = .2 ; r = .2 ; flag = 'c'\n",
    "\n",
    "def implied_volatility(price, S, K, t, r, flag):\n",
    "  return py_vollib_vectorized.vectorized_implied_volatility(\n",
    "    price, S, K, t, r, flag, q=0.0, on_error='ignore', model='black_scholes_merton',return_as='numpy') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Speed Analysis of the implied volatility Function: Per Option')\n",
    "%timeit implied_volatility(price, S, K, t, r, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyFFTW\n",
    "import pyfftw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import exp, pi, log, sqrt\n",
    "# from  numpy.fft import fft\n",
    "import pyfftw\n",
    "# @njit\n",
    "def heston_fft2(S0, K, T, r, kappa, theta, rho, zeta, v0, opt_type, N=1024, alpha=1.5):\n",
    "    eta = 0.25  # Grid spacing for the integration variable\n",
    "    lambda_u = 2 * pi / (N * eta)  # Grid spacing for log strike\n",
    "\n",
    "    # Adjustments for the damping factor\n",
    "    alpha = alpha  # Damping factor, typically 1 or 1.5\n",
    "\n",
    "    # Characteristic function for the Heston model as before\n",
    "    def heston_char(u):\n",
    "        t0 = 0.0 ; q = 0.0\n",
    "        m = log(S0) + (r - q) * (T - t0)\n",
    "        D = sqrt((rho * zeta * 1j * u - kappa) ** 2 + zeta ** 2 * (1j * u + u ** 2))\n",
    "        C = (kappa - rho * zeta * 1j * u - D) / (kappa - rho * zeta * 1j * u + D)\n",
    "        beta = ((kappa - rho * zeta * 1j * u - D) * (1 - exp(-D * (T - t0)))) / (zeta ** 2 * (1 - C * exp(-D * (T - t0))))\n",
    "        alpha = ((kappa * theta) / (zeta ** 2)) * ((kappa - rho * zeta * 1j * u - D) * (T - t0) - 2 * log((1 - C * exp(-D * (T - t0))) / (1 - C)))\n",
    "        return exp(1j * u * m + alpha + beta * v0)\n",
    "\n",
    "    # Array of discretized u values (integration variable)\n",
    "    u = np.arange(1, N) * eta\n",
    "    u = np.hstack((np.array([0.000001]), u))  # Avoid division by zero in calculations\n",
    "\n",
    "    # Weights for the integration\n",
    "    weights = np.ones(N)\n",
    "    weights[0] = 0.5  # Trapezoidal rule: first weight is 0.5\n",
    "    weights = weights * eta\n",
    "\n",
    "    # Damping factor applied to characteristic function\n",
    "    adjusted_char_fn = exp(-r * T) * (heston_char(u - (alpha + 1) * 1j) / (alpha ** 2 + alpha - u ** 2 + 1j * (2 * alpha + 1) * u))\n",
    "\n",
    "    # FFT calculation\n",
    "    fft_object = pyfftw.builders.rfft(adjusted_char_fn.real * weights, threads=4)\n",
    "    fft_values = fft_object()\n",
    "    fft_values = fft_values[:N // 2]  # Only need the first half of the FFT output\n",
    "\n",
    "    # Calculate strike prices corresponding to FFT output\n",
    "    strikes = S0 * exp(-lambda_u * np.arange(N // 2))\n",
    "\n",
    "    # Option prices\n",
    "    prices = np.exp(-alpha * np.log(strikes)) / pi * fft_values.real\n",
    "\n",
    "    # Find the index of the strike closest to K\n",
    "    index = np.argmin(np.abs(strikes - K))\n",
    "    price = prices[index]\n",
    "    return price if opt_type == 'p' else price + S0 - K * exp(-r * T)\n",
    "\n",
    "# Example call to function\n",
    "price = heston_fft2(S0=100, K=100, T=1, r=0.05, kappa=0.2, theta=0.04, rho=-0.7, zeta=0.2, v0=0.04, opt_type='p')\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fourier_Heston_Put(S0=100, K=100, T=1, r=0.05, kappa=0.2, theta=0.04, rho=-0.7, zeta=0.2, v0=0.04, opt_type='p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nelson_siegel_svensson.calibrate import calibrate_nss_ols\n",
    "yield_maturities = np.array([1/12, 2/12, 3/12, 4/12, 6/12, 1, 2, 3, 5, 7, 10, 20, 30])\n",
    "# yields  = np.array([5.30,5.39,5.50,5.50,5.44,5.11,4.33,3.98,3.70,3.66,3.61,3.98,3.84])\n",
    "# get the first row of the yield rates\n",
    "yields = yield_rates.iloc[0].values[1:].astype(np.float64)\n",
    "curve_fit, status = calibrate_nss_ols(yield_maturities,yields)\n",
    "# yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_fit, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Speed Analysis of Fourier_Heston_Put: Per Option')\n",
    "%timeit Fourier_Heston_Put(S0,K, T, r, kappa, theta, rho, zeta, v0, 'p', N = 1_012, z = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_implied_volatility(price, S, K, t, r, flag):\n",
    "    return py_vollib_vectorized.vectorized_implied_volatility(\n",
    "        price, S, K, t, r, flag, q=0.0, on_error='ignore', model='black_scholes_merton',return_as='numpy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volSurfaceLong = (\n",
    "    df[\n",
    "        (df['maturity'] > 0)\n",
    "        & (df['DaysSinceLastTraded'] >= Lookback_limit)\n",
    "    ]\n",
    ")\n",
    "volSurfaceLong['rate'] = volSurfaceLong['maturity'].apply(curve_fit) / 100\n",
    "volSurfaceLong         = volSurfaceLong.reset_index()\n",
    "\n",
    "# Data Cleaning: Sets the inf weighted values to the maximum weight \n",
    "volSurfaceLong.loc[ volSurfaceLong['Weight'] == np.inf , 'Weight'] = volSurfaceLong[ volSurfaceLong['Weight'] != np.inf ]['Weight'].max()\n",
    "volSurfaceLong['Weight'] = volSurfaceLong['Weight'] / volSurfaceLong['Weight'].mean()\n",
    "\n",
    "volSurface = volSurfaceLong.sample(n=250)\n",
    "_K          = volSurface['strike'].to_numpy()\n",
    "_P          = volSurface['price'].to_numpy()\n",
    "_T          = volSurface['maturity'].to_numpy()\n",
    "_r          = volSurface['rate'].to_numpy()\n",
    "_S          = volSurface['S'].to_numpy()\n",
    "opt_types   = volSurface['Type'].to_numpy(dtype=str)\n",
    "\n",
    "volSurface['IV'] = get_implied_volatility(price=_P, S=_S, K=_K, t=_T, r=_r, flag=opt_types)\n",
    "volSurface = volSurface[~volSurface.IV.isna()]\n",
    "print(f'Options Droped where IV == 0: {(~(volSurface.IV > 0)).sum()} , aka Options which the middpoint cannot be priced')\n",
    "volSurface = volSurface[volSurface.IV > 0]\n",
    "volSurface = volSurface[(volSurface['IV'] != np.inf) & (volSurface['IV'] != np.nan)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lookback_limit = dataset['DaysSinceLastTraded'].sort_values().unique()[-1]\n",
    "volSurfaceLong = (\n",
    "    df[\n",
    "        (df['maturity'] > 0)\n",
    "        & (df['DaysSinceLastTraded'] >= Lookback_limit)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_Heston(volSurface, v0, kappa, theta, zeta, rho):\n",
    "    \"\"\"Calculates the error between the Heston model and the market prices.\n",
    "    Arguments:\n",
    "        volSurface: DataFrame with the market prices.\n",
    "        v0: Initial variance.\n",
    "        kappa: Mean reversion speed.\n",
    "        theta: Long-run variance.\n",
    "        zeta: Volatility of volatility.\n",
    "        rho: Correlation between the variance and the asset.\n",
    "    \"\"\"\n",
    "    error = 0\n",
    "    for _, row in volSurface.iterrows():\n",
    "        P = row['price']\n",
    "        HP = Fourier_Heston_Put(S0=row['S'], K=row['strike'], v0=v0, kappa=kappa, theta=theta, zeta=zeta, rho=rho, T=row['maturity'], r=row['rate'], N=2048)\n",
    "        error += (P - HP)**2\n",
    "\n",
    "    return error / volSurface.shape[0]\n",
    "\n",
    "def get_resutls_array_Heston(volSurface, v0, kappa, theta, zeta, rho, N=10_000, z=64):\n",
    "    # Initialize the results array\n",
    "    results = -np.ones(volSurface.shape[0])\n",
    "    # reset the index of the options dataframe\n",
    "    volSurface.index = np.arange(0, volSurface.shape[0])\n",
    "    # loop through the rows of the options dataframe and run the Fourier_Heston_Put function\n",
    "    for idx, row in volSurface.iterrows():\n",
    "        results[idx] = Fourier_Heston_Put(S0=int(row['S']), K=int(row['strike']), v0=v0, kappa=kappa, theta=theta, zeta=zeta, rho=rho, T=row['maturity'], r=row['rate'], N=N, opt_type=row['Type'],z=z)\n",
    "    return results\n",
    "\n",
    "def get_resutls_df_Heston(volSurface, v0, kappa, theta, zeta, rho, N=2048, z=100):\n",
    "    observed = volSurface.copy(deep=True)\n",
    "    heston = volSurface.copy(deep=True)\n",
    "    observed['source'] = 'Observed'\n",
    "    heston['source'] = 'Heston Model'\n",
    "\n",
    "    heston_prices = [] \n",
    "    implied_volatilities = []\n",
    "    for _, row in volSurface.iterrows():\n",
    "        heston_price = Fourier_Heston_Put(S0=row['S'], K=row['strike'], v0=v0, kappa=kappa, theta=theta, zeta=zeta, rho=rho, T=row['maturity'], r=row['rate'], N=N, opt_type=row['Type'], z=z)\n",
    "        heston_prices.append(heston_price)\n",
    "        # np.array(... , ndmin=1) So the type of the input is compatible with what numba expects\n",
    "        maturity  = np.array(row['maturity'],ndmin=1)\n",
    "        observed_price  = np.array(heston_price,ndmin=1)\n",
    "        S0 = np.array(row['S'],ndmin=1)\n",
    "        K  = np.array(row['strike'],ndmin=1)\n",
    "        r  = np.array(row['rate'],ndmin=1)\n",
    "        option_type = np.array(row['Type'],ndmin=1)\n",
    "        implied_volatility = get_implied_volatility(price=observed_price, S=S0, K=K, t=maturity, r=r, flag=option_type)\n",
    "        implied_volatilities.append(implied_volatility[0])\n",
    "\n",
    "    heston['price'] = heston_prices\n",
    "    heston['IV']    = implied_volatilities\n",
    "\n",
    "    return pd.concat([observed, heston])\n",
    "\n",
    "def get_error_df_Heston(volSurface, v0, kappa, theta, zeta, rho, diff='Price', error='Error', weighted=True, N=10_000, z=64):\n",
    "    if   error == 'Error':          _name = f'Weighted Error {diff}'             if weighted else f'Error {diff}'\n",
    "    elif error == 'Perc Error':     _name = f'Weighted Persentage Error {diff}'  if weighted else f'Persentage Error {diff}'\n",
    "    elif error == 'Squared Error':  _name = f'Weighted Squared Error {diff}'     if weighted else f'Squared Error {diff}'\n",
    "    else: raise Exception(\"Error: variable 'error' is not defined correctly\")\n",
    "    \n",
    "    results_df = {'strike':[], 'maturity':[], _name:[], 'Opt. Type':[], 'Weight':[]}\n",
    "\n",
    "    for _, row in volSurface.copy(deep=True).iterrows():\n",
    "        _P = Fourier_Heston_Put(S0=row['S'], K=row['strike'], v0=v0, kappa=kappa, theta=theta, zeta=zeta, rho=rho, T=row['maturity'], r=row['rate'], N=N, z=z, opt_type=row['Type'])\n",
    "        # np.array(... , ndmin=1) So the type of the input is compatible with what numba expects\n",
    "        _T  = np.array(row['maturity'],ndmin=1)\n",
    "        _C  = np.array(_P,ndmin=1)\n",
    "        _P  = np.array(row['price'],ndmin=1)\n",
    "        _S0 = np.array(row['S'],ndmin=1)\n",
    "        _K  = np.array(row['strike'],ndmin=1)\n",
    "        _r  = np.array(row['rate'],ndmin=1)\n",
    "        _OT = np.array(row['Type'],ndmin=1)\n",
    "\n",
    "        _IV  = get_implied_volatility(price=_C, S=_S0, K=_K, t=_T, r=_r, flag=_OT)\n",
    "        _IV2 = get_implied_volatility(price=row['price'], S=_S0, K=_K, t=_T, r=_r, flag=_OT)\n",
    "\n",
    "        if error    == 'Error':\n",
    "            if diff == 'IV':  _error  = (_IV - _IV2) *                (row['Weight'] if weighted else 1)\n",
    "            else           :  _error  = (_C - _P) *                   (row['Weight'] if weighted else 1)\n",
    "        elif error  == 'Perc Error':\n",
    "            if diff == 'IV':  _error  = ((_IV - _IV2)/_IV2) * 100 *   (row['Weight'] if weighted else 1)\n",
    "            else           :  _error  = ((_C - _P)/_P) * 100 *        (row['Weight'] if weighted else 1)\n",
    "        elif error  == 'Squared Error':\n",
    "            if diff == 'IV':  _error  = (_IV - _IV2)**2 *             (row['Weight'] if weighted else 1)\n",
    "            else           :  _error  = (_C - _P)**2 *                (row['Weight'] if weighted else 1)\n",
    "\n",
    "        results_df[_name].append(_error[0])\n",
    "        results_df['maturity'].append(_T[0])\n",
    "        results_df['strike'].append(_K[0])\n",
    "        results_df['Opt. Type'].append(_OT[0])\n",
    "        results_df['Weight'].append(row['Weight']*10)\n",
    "\n",
    "    return pd.DataFrame(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from volSurface DataFrame\n",
    "_K      = volSurface['strike'].to_numpy()\n",
    "_C      = volSurface['price'].to_numpy()\n",
    "_type   = volSurface['Type'].to_numpy(dtype=str)\n",
    "_T      = volSurface['maturity'].to_numpy()\n",
    "_r      = volSurface['rate'].to_numpy()\n",
    "_S      = np.full_like(_K, S0)\n",
    "_IV     = volSurface['IV'].to_numpy()\n",
    "_Weight = volSurface['Weight'].to_numpy()\n",
    "\n",
    "# Initial parameters and bounds for optimization\n",
    "params = {\n",
    "    \"v0\": {\"x0\": 0.002874, \"lbub\": [1e-3, 1.2]},\n",
    "    \"kappa\": {\"x0\": 1.6891, \"lbub\": [1e-3, 10]},\n",
    "    \"theta\": {\"x0\": 0.0190, \"lbub\": [1e-3, 1.2]},\n",
    "    \"zeta\": {\"x0\": 3.7472, \"lbub\": [1e-2, 4]},\n",
    "    \"rho\": {\"x0\": -0.2731, \"lbub\": [-1, 1]}\n",
    "}\n",
    "x0 = [param[\"x0\"] for _, param in params.items()]\n",
    "bnds = [param[\"lbub\"] for _, param in params.items()]\n",
    "\n",
    "# Objective function: Squared Error\n",
    "def SqErr(x):\n",
    "    v0, kappa, theta, zeta, rho = x\n",
    "    \n",
    "    # Calculate prices using Heston Model\n",
    "    Price_Heston = get_resutls_array_Heston(\n",
    "        volSurface, v0, kappa, theta, zeta, rho, N=1_012, z=24\n",
    "    )\n",
    "    \n",
    "    # Calculate implied volatilities\n",
    "    IV_Heston = get_implied_volatility(\n",
    "        price=Price_Heston, S=_S, K=_K, t=_T, r=_r, flag=_type\n",
    "    )\n",
    "    \n",
    "    # Handle undefined IV calculations\n",
    "    diff = IV_Heston - _IV\n",
    "    idx = np.isnan(diff) | np.isinf(diff)\n",
    "    diff[idx] = 0 - _IV[idx]\n",
    "    IV_Heston[idx] = 0\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = sqrt(np.mean((diff * 100) ** 2 * _Weight))\n",
    "    \n",
    "    # Debugging info\n",
    "    zeros = int(np.where(IV_Heston == 0, 1, 0).sum())\n",
    "    wmae  = np.mean(np.abs(diff * 100) * _Weight)\n",
    "    print_debug_info(v0, kappa, theta, zeta, rho, wmae, idx, zeros, rmse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Debugging info printer\n",
    "def print_debug_info(v0, kappa, theta, zeta, rho, wmae, idx, zeros, rmse):\n",
    "    print(\n",
    "        f\">>v0={v0:.4f}; kappa={kappa:.4f}; theta={theta:.4f}; \"\n",
    "        f\"zeta={zeta:.4f}; rho={rho:7.4f} | WMAE(IV): {wmae:.5e} | \"\n",
    "        f\"Nulls: {idx.sum()}/{idx.shape[0]} | Zeros: {zeros}/{idx.shape[0]} | \"\n",
    "        f\"WRMSE(IV): {rmse:.5e}\"\n",
    "    )\n",
    "\n",
    "# Run optimization\n",
    "result = minimize(\n",
    "    SqErr, x0, tol=1e-5, method='SLSQP',\n",
    "    options={'maxiter': 80, 'ftol': 1e-5, 'disp': True},\n",
    "    bounds=bnds, jac='3-point'\n",
    ")\n",
    "\n",
    "# Extract optimized parameters\n",
    "v0, kappa, theta, zeta, rho = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def heston_daily_volSurface(date, underlying_ticker):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(f\"options_data/contracts-{underlying_ticker}.csv\")\n",
    "\n",
    "    def filter_by_time_diff(x):\n",
    "        current_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        time_diff = datetime.strptime(x['expiration_date'], \"%Y-%m-%d\").days -current_date.days\n",
    "        return time_diff >= 0 and time_diff < 14\n",
    "    \n",
    "    contracts = df.groupby('expiration_date').filter(filter_by_time_diff)\n",
    "    \n",
    "    # for each contract, pick the aggregates\n",
    "\n",
    "    contract_aggs = contracts.groupby(['expiration_date', 'trading_date']).filter(lambda x: x['trading_date'] == date)\n",
    "    \n",
    "    # \n",
    "\n",
    "    return volSurface\n",
    "\n",
    "def heston_daily_parameters(dailyVolSurface):\n",
    "\t# Extract data from dailyVolSurface DataFrame\n",
    "    _K = dailyVolSurface['strike'].to_numpy()\n",
    "\n",
    "    _C = dailyVolSurface['price'].to_numpy()\n",
    "    _type   = dailyVolSurface['Type'].to_numpy(dtype=str)\n",
    "    _T      = dailyVolSurface['maturity'].to_numpy()\n",
    "    _r      = dailyVolSurface['rate'].to_numpy()\n",
    "    _S      = np.full_like(_K, S0)\n",
    "    _IV     = dailyVolSurface['IV'].to_numpy()\n",
    "    _Weight = dailyVolSurface['Weight'].to_numpy()\n",
    "\n",
    "    # Initial parameters and bounds for optimization\n",
    "    params = {\n",
    "        \"v0\": {\"x0\": 0.002874, \"lbub\": [1e-3, 1.2]},\n",
    "        \"kappa\": {\"x0\": 1.6891, \"lbub\": [1e-3, 10]},\n",
    "        \"theta\": {\"x0\": 0.0190, \"lbub\": [1e-3, 1.2]},\n",
    "        \"zeta\": {\"x0\": 3.7472, \"lbub\": [1e-2, 4]},\n",
    "        \"rho\": {\"x0\": -0.2731, \"lbub\": [-1, 1]}\n",
    "    }\n",
    "    x0 = [param[\"x0\"] for _, param in params.items()]\n",
    "    bnds = [param[\"lbub\"] for _, param in params.items()]\n",
    "    result = minimize(\n",
    "    SqErr, x0, tol=1e-5, method='SLSQP',\n",
    "    options={'maxiter': 80, 'ftol': 1e-5, 'disp': True},\n",
    "    bounds=bnds, jac='3-point'\n",
    "\t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guidelight-Popvxsqg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
