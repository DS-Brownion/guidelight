{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.sparse as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import QuantLib as ql\n",
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt 1\n",
    "failure from the lack of advanced knowledge of numerical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[201. -50.   0. ...   0.   0.   0.]\n",
      " [-50. 201. -50. ...   0.   0.   0.]\n",
      " [  0. -50. 201. ...   0.   0.   0.]\n",
      " ...\n",
      " [  0.   0.   0. ... 201. -50.   0.]\n",
      " [  0.   0.   0. ... -50. 201. -50.]\n",
      " [  0.   0.   0. ...   0. -50. 201.]]\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00666176e-03 2.01230991e-03 ... 2.01230991e-03\n",
      "  1.00666176e-03 3.88555122e-18]\n",
      " [0.00000000e+00 2.01230991e-03 4.02259358e-03 ... 4.02259358e-03\n",
      "  2.01230991e-03 7.76719002e-18]\n",
      " ...\n",
      " [0.00000000e+00 2.01230991e-03 4.02259358e-03 ... 4.02259358e-03\n",
      "  2.01230991e-03 7.76719002e-18]\n",
      " [0.00000000e+00 1.00666176e-03 2.01230991e-03 ... 2.01230991e-03\n",
      "  1.00666176e-03 3.88555122e-18]\n",
      " [0.00000000e+00 3.88555122e-18 7.76719002e-18 ... 7.76719002e-18\n",
      "  3.88555122e-18 1.49975978e-32]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JoyChang\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\linalg\\_dsolve\\linsolve.py:214: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
      "  warn('spsolve requires A be CSC or CSR matrix format',\n"
     ]
    }
   ],
   "source": [
    "# Description: Crank-Nicholson Scheme for 2D Heat Equation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Crank-Nicholson Scheme\n",
    "\n",
    "\n",
    "# Parameters\n",
    "width = 1.0     # lower-end of the rod\n",
    "height = 1.0    # upper-end of the rod\n",
    "N = 100      # number of width divisions\n",
    "K = 100    # number of height divisions\n",
    "dx = width / N  # spatial step size\n",
    "dy = height / K\n",
    "C = 1.0 # thermal diffusivity\n",
    "dt = 0.01   # time step size\n",
    "# crank-nicolson constant\n",
    "i_c = 0.5 \n",
    "theta = i_c * C*dt/(dx**2)\n",
    "alpha = (1 - i_c) * C * dt /(dx**2)\n",
    "T = 0.1     # total time\n",
    "M = int(T / dt)  # number of time steps\n",
    "\n",
    "# Spatial grid\n",
    "params = np.linspace(0, width, N)\n",
    "y = np.linspace(0, height, K)\n",
    "X,Y = np.meshgrid(params, y)\n",
    "u = np.sin(np.pi * X)* np.sin(np.pi * Y)\n",
    "\n",
    "# diagonal length is defined by the number of grid points\n",
    "i_grid_size = (K-1) * (N-1)\n",
    "# create the coefficient matrix\n",
    "# diagonal of a 1-4*Lambda \n",
    "\n",
    "offdiagonals = np.zeros(i_grid_size - 1)\n",
    "offdiagonals[(np.arange(1, i_grid_size)) % (K -1) != 0] = -theta\n",
    "# np.fill(diagonals[(np.arange(1, i_grid_size)) % (K -1) != 0])\n",
    "\n",
    "# diagonals.fill(-theta)\n",
    "diagsVec = [-theta , offdiagonals, 1 + 4 * theta, offdiagonals, -theta]\n",
    "# diags[:, [0, 1, 3, 4]] = -theta\n",
    "# diags[:,2] = 1 + 4 * theta\n",
    "# #zeros from BCs\n",
    "offsets = [-N+1, -1, 0, 1, N-1]\n",
    "\n",
    "\n",
    "A = scipy.sparse.diags(diagsVec, offsets, shape=((K-1) * (N-1), (K-1) * (N-1))).toarray()\n",
    "print(A)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(u)\n",
    "\n",
    "\n",
    "\n",
    "# Time iteration\n",
    "#PUT 3D ARRAY\n",
    "# u_hist = [u.copy()] # history of u for plotting\n",
    "u_hist = np.zeros(shape=(M + 1, N, K))\n",
    "u_hist[0,:,:] = u\n",
    "for k in range(1, M+1):\n",
    "    b = np.zeros((K-1) * (N-1))\n",
    "    # print(\"u_n: \", u)\n",
    "    for i in range(1, N-1):\n",
    "        for i in range(1, K-1): \n",
    "            index = (i-1) * (N-1)+ i -1  # Adjusted index calculation for interior points\n",
    "            # b[index] = alpha * u[i+1, j] + alpha * u[i, j + 1] + (1- 4*alpha) * u[i, j] \\\n",
    "            # + alpha * u[i - 1, j] + alpha * u[i, j -1]\n",
    "            b[index] = (1 - 4 * alpha) * u[i,i] + alpha * (u[i+1,i] + u[i,i+1] + u[i-1,i] + u[i,i-1])\n",
    "   \n",
    "    u_new = sp.linalg.spsolve(A, b)\n",
    "    u_new_2d = np.zeros_like(u)\n",
    "    index = 0\n",
    "    # for i in range(1, N):\n",
    "    #     for j in range(1, K):\n",
    "    #         u_new_2d[i, j] = u_new[index]\n",
    "    #         index += 1\n",
    "\n",
    "\n",
    "    u_new_2d[1:N, 1:K] = u_new.reshape(N-1, K-1)\n",
    "\n",
    "    u = u_new_2d\n",
    "    u_hist[k,:,:] = u_new_2d\n",
    "\n",
    "u_hist = np.array(u_hist)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findAi(S2, S1, S0, dt, r, sigma, dS_plus, dS_minus, grid_size):\n",
    "#     Sph = S2 - S1\n",
    "#     Smh = S1 - S0\n",
    "\n",
    "#     ai = (sigma**2 * S1**2 / (Sph * dS_plus[:-1]) + r * S1 / dS_plus[:-1]) * dt * 0.5\n",
    "#     ci = (sigma**2 * S1**2 / (Smh * dS_minus[:-1]) - r * S1 / dS_minus[:-1]) * dt * 0.5\n",
    "#     ai = np.append(ai, (sigma**2 * S1**2 / (Sph[-1] * dS_plus[-1]) + r * S1 / dS_plus[-1]) * dt * 0.5)\n",
    "#     ci = np.append(ci, (sigma**2 * S1**2 / (Smh[-1] * dS_minus[-1]) - r * S1 / dS_minus[-1]) * dt * 0.5)\n",
    "#     bi = -(ai + ci + r * dt)\n",
    "    \n",
    "#     return scipy.sparse.diags([ci, bi, ai], [-1, 0, 1], shape=(grid_size, grid_size))\n",
    "\n",
    "\n",
    "# def approximate_black_scholes(s_grid,  K, T, r, sigma, t_i = 1000, option_type = 'call'):\n",
    "# \tdt = T / t_i\n",
    "# \tN = s_grid.shape[0]\n",
    "# \tv = np.zeros((t_i, N))\n",
    "# \tv[0, :] = np.maximum(s_grid - K, 0) if option_type == 'call' else np.maximum(K - s_grid, 0)\n",
    "# \tdS_plus = np.diff(s_grid)  # dS[i] = s_grid[i+1] - s_grid[i]\n",
    "# \tdS_minus = np.insert(dS_plus[:-1], 0, dS_plus[0]) \n",
    "\n",
    "# \tfor n in range(t_i - 1):\n",
    "# \t\tif option_type == 'call':\n",
    "# \t\t\tv[n + 1, 0] = 0  # Call option value at nearly zero asset price\n",
    "# \t\t\tv[n + 1, -1] = s_grid[-1] - K * np.exp(-r * (T - dt * (n + 1)))\n",
    "# \t\telif option_type == 'put':\n",
    "# \t\t\tv[n + 1, 0] = K * np.exp(-r * (T - dt * (n + 1)))\n",
    "# \t\t\tv[n + 1, -1] = 0  # Put option value at the upper boundary\n",
    "# \t\tAi = findAi(s_grid[2:], s_grid[1:-1], s_grid[: -2], dt, r, sigma, dS_plus, dS_minus, N - 2)\n",
    "# \t\tAi_dense = Ai.toarray()\n",
    "#         # Use numpy.linalg.solve to solve the linear system\n",
    "# \t\tv[n + 1, 1:-1] = np.linalg.solve(Ai_dense, v[n, 1:-1])\n",
    "\t\t\n",
    "\t\n",
    "# \treturn v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical solution for European call option: -13.329095232525422\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "S_0 = 100\n",
    "K = 100\n",
    "T = 1\n",
    "r = 0.05\n",
    "sigma = 0.2\n",
    "d1 = (math.log(S_0 / K) + (r + 0.5 * sigma**2) * T) / (sigma * math.sqrt(T))\n",
    "d2 = d1 - sigma * math.sqrt(T)\n",
    "\n",
    "call_option_value = (S_0 * math.exp(-r * T) * (math.erfc(d1 * math.sqrt(2)) / 2) - K * math.exp(-r * T) * (math.erfc(d2 * math.sqrt(2)) / 2))\n",
    "\n",
    "print(\"Analytical solution for European call option:\", call_option_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAi(S2, S1, S0, dt, r, sigma, dS_plus, dS_minus, grid_size):\n",
    "    Sph = S2 - S1\n",
    "    Smh = S1 - S0\n",
    "\n",
    "    ai = (sigma**2 * S1**2 / (Sph * dS_plus[:-1]) + r * S1 / dS_plus[:-1]) * dt * 0.5\n",
    "    ci = (sigma**2 * S1**2 / (Smh * dS_minus[:-1]) - r * S1 / dS_minus[:-1]) * dt * 0.5\n",
    "    ai = np.append(ai, (sigma**2 * S1**2 / (Sph[-1] * dS_plus[-1]) + r * S1 / dS_plus[-1]) * dt * 0.5)\n",
    "    ci = np.append(ci, (sigma**2 * S1**2 / (Smh[-1] * dS_minus[-1]) - r * S1 / dS_minus[-1]) * dt * 0.5)\n",
    "    bi = -(ai + ci + r * dt)\n",
    "    return scipy.sparse.diags([ci, bi, ai], [-1, 0, 1], shape=(grid_size, grid_size))\n",
    "\n",
    "\n",
    "def approximate_black_scholes(s_grid, K, T, rho, sigma, t_i = 1000, option_type = 'call'):\n",
    "    dt = T / t_i\n",
    "    N = s_grid.shape[0]\n",
    "    v = np.zeros((t_i, N))\n",
    "    v[0, :] = np.maximum(s_grid - K, 0) if option_type == 'call' else np.maximum(K - s_grid, 0)\n",
    "    \n",
    "\n",
    "    for n in range(t_i - 1):\n",
    "        \n",
    "        if option_type == 'call':\n",
    "            v[n + 1, 0] = 0  # Call option value at nearly zero asset price\n",
    "            v[n + 1, -1] = s_grid[-1] - K * np.exp(-rho * (T - dt * (n + 1)))\n",
    "        elif option_type == 'put':\n",
    "            v[n + 1, 0] = K * np.exp(-rho * (T - dt * (n + 1)))\n",
    "            v[n + 1, -1] = 0  # Put option value at the upper boundary\n",
    "        dS = np.diff(s_grid)\n",
    "        Ai = findAi(s_grid[2:], s_grid[1:-1], s_grid[: -2], dt, rho, sigma, dS, N)\n",
    "        v[n + 1, 1:-1] = sp.linalg.spsolve(Ai, v[n, 1:-1])\n",
    "        \n",
    "        \n",
    "        \n",
    "    return v[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "findAi() missing 1 required positional argument: 'grid_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m option_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate the option price\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m option_price \u001b[38;5;241m=\u001b[39m approximate_black_scholes(s_grid, K, T, rho, sigma, t_i, option_type)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculated Call Option Price: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moption_price\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 29\u001b[0m, in \u001b[0;36mapproximate_black_scholes\u001b[1;34m(s_grid, K, T, rho, sigma, t_i, option_type)\u001b[0m\n\u001b[0;32m     27\u001b[0m         v[n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Put option value at the upper boundary\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     dS \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiff(s_grid)\n\u001b[1;32m---> 29\u001b[0m     Ai \u001b[38;5;241m=\u001b[39m findAi(s_grid[\u001b[38;5;241m2\u001b[39m:], s_grid[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], s_grid[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], dt, rho, sigma, dS, N)\n\u001b[0;32m     30\u001b[0m     v[n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mspsolve(Ai, v[n, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: findAi() missing 1 required positional argument: 'grid_size'"
     ]
    }
   ],
   "source": [
    "# Setup the parameters for the test case\n",
    "S0 = 100\n",
    "K = 100\n",
    "T = 1\n",
    "rho = 0.05\n",
    "sigma = 0.2\n",
    "s_grid = np.linspace(50, 150, 100)  # Create a grid for the underlying asset prices\n",
    "t_i = 1000  # Number of time steps\n",
    "option_type = 'call'\n",
    "\n",
    "# Calculate the option price\n",
    "option_price = approximate_black_scholes(s_grid, K, T, rho, sigma, t_i, option_type)\n",
    "print(f\"Calculated Call Option Price: {option_price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def option_price(sigma, S, K, T, rho, t_i, option_type):\n",
    "    s_grid = np.linspace(0, 100, 100)\n",
    "    return approximate_black_scholes(s_grid, K, T, rho, sigma, t_i, option_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_implied_volatility(target_price, s_grid, K, T, rho, t_i, option_type, tol=0.001, max_iter=100):\n",
    "    sigma_low, sigma_high = 0.01, 2.0  # Initial bounds for volatility\n",
    "    for i in range(max_iter):\n",
    "        sigma_mid = (sigma_low + sigma_high) / 2\n",
    "        mid_price = approximate_black_scholes(s_grid, K, T, rho, sigma_mid, t_i, option_type)\n",
    "        \n",
    "        if mid_price < target_price:\n",
    "            sigma_low = sigma_mid\n",
    "        else:\n",
    "            sigma_high = sigma_mid\n",
    "        \n",
    "        if abs(mid_price - target_price) < tol:\n",
    "            return sigma_mid, i+1  # Return the found volatility and iteration count\n",
    "        \n",
    "    return sigma_mid, max_iter  # Return the best guess and iteration count if convergence criteria not met\n",
    "\n",
    "# Example usage:\n",
    "  # Example market price of the option\n",
    "s_grid = np.linspace(50, 150, 100)  # Example grid for underlying asset prices, adjust as needed\n",
    "K = 100  # Strike price\n",
    "T = 1  # Time to maturity in years\n",
    "rho = 0.05  # Risk-free interest rate\n",
    "t_i = 365  # Number of time steps, assuming daily steps over a year for simplicity\n",
    "option_type = 'call'  # Option type ('call' or 'put')\n",
    "target_market_price = 50\n",
    "\n",
    "implied_vol, iterations = find_implied_volatility(target_market_price, s_grid, K, T, rho, t_i, option_type)\n",
    "print(f\"Implied Volatility: {implied_vol:.4f} found in {iterations} iterations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capm(risk_free_rate, beta, market_return):\n",
    "    return risk_free_rate + beta * (market_return - risk_free_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: Neural parameter optimization for the heston process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuralized Heston Process\n",
    "https://stackoverflow.com/questions/64456893/quantlib-python-heston-model-generate-path-get-boost-assertion-failed-px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = ql.Date(21, 10, 2020)\n",
    "daycount = ql.Actual360()\n",
    "calendar = ql.TARGET()\n",
    "r_ts = ql.YieldTermStructureHandle(ql.FlatForward(today, 0.02, daycount))\n",
    "d_ts = ql.YieldTermStructureHandle(ql.FlatForward(today, 0.01, daycount))\n",
    "v0, kappa, theta, sigma, rho = 0.03, 10, 0.03, 0.4, 0.3\n",
    "hs_process = ql.HestonProcess(r_ts, d_ts, ql.QuoteHandle(ql.SimpleQuote(100)), v0, kappa, theta, sigma, rho)\n",
    "\n",
    "\n",
    "timestep = 50\n",
    "length = 1.0\n",
    "rng = ql.GaussianRandomSequenceGenerator(ql.UniformRandomSequenceGenerator(2*timestep, ql.UniformRandomGenerator()))\n",
    "times = list(ql.TimeGrid(length, timestep))\n",
    "seq = ql.GaussianMultiPathGenerator(hs_process, times, rng)\n",
    "\n",
    "path_1 = seq.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heston_predictions(v0, kappa, theta, sigma, rho, risk_free_rate_quote: ql.SimpleQuote):\n",
    "    today = ql.Date().todaysDate()\n",
    "    # daycount convention, not the difference in days\n",
    "    daycount = ql.Actual360()\n",
    "    calendar = ql.TARGET()\n",
    "\n",
    "    # Convert SimpleQuote to QuoteHandle for use in FlatForward\n",
    "    risk_free_rate_handle = ql.QuoteHandle(risk_free_rate_quote)\n",
    "\n",
    "    # Using FlatForward with QuoteHandle and day count convention\n",
    "    r_ts = ql.YieldTermStructureHandle(ql.FlatForward(today, risk_free_rate_handle, daycount))\n",
    "    d_ts = ql.YieldTermStructureHandle(ql.FlatForward(today, risk_free_rate_handle, daycount))\n",
    "\n",
    "    hs_process = ql.HestonProcess(r_ts, d_ts, ql.QuoteHandle(ql.SimpleQuote(100)), v0, kappa, theta, sigma, rho)\n",
    "\n",
    "    timestep = 50\n",
    "    length = 0.5  # Simulation length in years\n",
    "    rng = ql.GaussianRandomSequenceGenerator(ql.UniformRandomSequenceGenerator(2*timestep, ql.UniformRandomGenerator()))\n",
    "    times = list(ql.TimeGrid(length, timestep))\n",
    "    seq = ql.GaussianMultiPathGenerator(hs_process, times, rng)\n",
    "\n",
    "    sample_path = seq.next()\n",
    "    multi_path = sample_path.value()\n",
    "    print(type(multi_path[0]), type(multi_path[1]))\n",
    "    # Extracting asset price and volatility paths\n",
    "    asset_price_path = torch.tensor([multi_path[0][i] for i in range(len(times))])\n",
    "    volatility_path = torch.tensor([multi_path[1][i] for i in range(len(times))])\n",
    "\n",
    "    return asset_price_path, volatility_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'QuantLib.QuantLib.Path'> <class 'QuantLib.QuantLib.Path'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([100.0000,  99.0864,  99.2784, 100.1705,  96.2303,  94.5728,  96.8407,\n",
       "          96.1655,  97.1993,  99.8300,  98.6234, 105.4523, 102.2115, 104.0598,\n",
       "          99.6415, 101.5727, 101.2879, 101.0077, 106.2235, 108.6584, 107.9149,\n",
       "         107.0027, 105.9356, 105.3013, 107.4736, 109.9460, 111.2336, 110.3985,\n",
       "         110.7462, 115.4014, 115.2520, 116.8513, 118.0406, 117.2273, 119.3657,\n",
       "         116.0170, 116.8188, 116.5752, 117.9612, 116.8807, 116.0364, 112.5169,\n",
       "         112.3595, 113.0313, 112.8886, 115.3310, 113.2027, 116.5040, 116.8439,\n",
       "         118.9375, 117.8755]),\n",
       " tensor([0.0300, 0.0327, 0.0327, 0.0487, 0.0314, 0.0304, 0.0367, 0.0466, 0.0551,\n",
       "         0.0576, 0.0608, 0.0859, 0.0772, 0.0903, 0.0753, 0.0823, 0.0632, 0.0554,\n",
       "         0.0604, 0.0490, 0.0590, 0.0537, 0.0449, 0.0558, 0.0602, 0.0595, 0.0451,\n",
       "         0.0481, 0.0367, 0.0416, 0.0457, 0.0674, 0.0717, 0.0697, 0.0611, 0.0708,\n",
       "         0.0640, 0.0581, 0.0477, 0.0405, 0.0418, 0.0358, 0.0350, 0.0284, 0.0291,\n",
       "         0.0342, 0.0421, 0.0518, 0.0399, 0.0358, 0.0222]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heston_predictions(0.03, 10, 0.03, 0.4, 0.3, ql.SimpleQuote(0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather daily historical market data\n",
    "# daily_market_vols = [np.array([...]) for day in range(num_days)]\n",
    "# daily_spot_prices = [np.array([...]) for day in range(num_days)]\n",
    "# daily_strike_prices = [np.array([...]) for day in range(num_days)]\n",
    "# daily_maturity_dates = [np.array([...]) for day in range(num_days)]\n",
    "\n",
    "# # Estimate daily Heston model parameters\n",
    "# daily_heston_parameters = []\n",
    "# for i in range(num_days):\n",
    "#     parameters = estimate_historical_parameters(daily_market_vols[i], daily_spot_prices[i], daily_strike_prices[i], daily_maturity_dates[i])\n",
    "#     daily_heston_parameters.append(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def daily_heston_parameters(daily_market_vols, daily_strike_prices, daily_spot_prices, daily_maturity_dates):\n",
    "\tdaily_heston_parameter = []\n",
    "\t\n",
    "\t\t# Estimate Heston model parameters for each day\n",
    "\tparameters = estimate_historical_parameters(daily_market_vols, daily_strike_prices, daily_spot_prices, daily_maturity_dates)\n",
    "\tdaily_heston_parameters.append(parameters)\n",
    "\treturn daily_heston_parameter\n",
    "def calculate_hist_parameters(market_vols, spot_prices, strike_prices, maturity_dates, num_days):\n",
    "\tfor i in range(num_days):\n",
    "\t\tdaily_parameter = daily_heston_parameters(market_vols[i], spot_prices[i], strike_prices[i], maturity_dates[i])\n",
    "\t\tdaily_heston_parameters.append(daily_parameter)\n",
    "\n",
    "\treturn daily_heston_parameters\n",
    "\n",
    "class heston(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(heston, self).__init__()\n",
    "\t\tself.mu = 0.0\n",
    "\t\tself.kappa = 0.0\n",
    "\t\tself.theta = 0.0\n",
    "\t\tself.xi = 0.0\n",
    "\t\tself.rho = 0.0\n",
    "\n",
    "\tdef forward(self, params):\n",
    "\t\tself.mu, self.kappa, self.theta, self.xi, self.rho = params\n",
    "\t\tsp_path, v_path = heston_predictions(self.mu, self.kappa, self.theta, self.xi, self.rho)\n",
    "\t\ts_mean = sp_path.mean()\n",
    "\t\tp_mean = sp_path.mean()\n",
    "\t\ts_dev = sp_path - s_mean\n",
    "\t\tv_dev = v_path - p_mean\n",
    "\n",
    "\t\tcovariance = (s_dev * v_dev).mean()\n",
    "\t\te_x = s_mean\n",
    "\t\tbeta = covariance / s_dev.std()\n",
    "\t\treturn e_x, beta\n",
    "\t\n",
    "\n",
    "class param_LSTM(nn.Module):\n",
    "\tdef __init__(self, device='cpu'):\n",
    "\t\tsuper(param_LSTM, self).__init__()\n",
    "\t\t# utilizing 3 layers of LSTM\n",
    "\t\tself.lstms = nn.ModuleList([\n",
    "            nn.LSTM(128, hidden_size=64, batch_first=True),\n",
    "            nn.LSTM(64, hidden_size=32, batch_first=True),\n",
    "            nn.LSTM(32, hidden_size=16, batch_first=True)  # Ensure consistency in input_size\n",
    "        ])\n",
    "\t\tself.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(2)])\n",
    "\n",
    "\t\tself.device = device\n",
    "\t\tself.linear = nn.Linear(16, 1)\n",
    "\t\tself.to(device)\n",
    "\t\n",
    "\tdef forward(self,params):\n",
    "\t\t\n",
    "\t\t# since we would only need the last output of the LSTM\n",
    "\t\t\n",
    "\t\tparams = params.to(self.device)\n",
    "\t\tfor i in range(len(self.lstms)):\n",
    "\t\t\tparams, _ = self.lstms[i](params)\n",
    "\t\t\t# apply residual connection\n",
    "\t\t\tif i < len(self.dropouts):\n",
    "\t\t\t\tparams = self.dropouts[i](params)\n",
    "\t\tparams = params[ -1, :]\n",
    "\t\tparams = self.linear(params)\n",
    "\t\t\n",
    "\t\treturn params\n",
    "\t\n",
    "\tdef train_loop(self, train_h, train_eb, val_h, val_eb):\n",
    "\t\t# chooses gpu if available, otherwise cpu\n",
    "\t\t\n",
    "\t\t# chose the adam optimizer for the gradient descent\n",
    "\t\ttrain_h, train_eb = train_h.to(self.device), train_eb.to(self.device)\n",
    "\t\tval_h, val_eb = val_h.to(self.device), val_eb.to(self.device)\n",
    "\t\toptimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
    "\t\t# currently using MSE loss function to fit the model ()\n",
    "\t\tloss_fn = nn.MSELoss()\n",
    "\n",
    "\t\t# training the model for 100 epochs\n",
    "\t\tfor epoch in range(100):\n",
    "\t\t\t# set to training mode\n",
    "\t\t\tself.train()\n",
    "\n",
    "\t\t\t# zero the gradients otherwise they would accumulate\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tpred = self(train_h)\n",
    "\t\t\tloss = loss_fn(pred, train_eb)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\n",
    "\t\t\t# set to evaluation mode\n",
    "\t\t\tself.eval()\n",
    "\t\t\twith torch.no_grad():  # Inference mode, gradients not computed\n",
    "\t\t\t\tval_pred = self(val_h)\n",
    "\t\t\t\tval_loss = loss_fn(val_pred, val_eb)\n",
    "\t\t\t\n",
    "\t\t\tprint(f'Epoch {epoch} loss: {loss.item()}', f'Validation loss: {val_loss.item()}')\n",
    "\n",
    "\n",
    "class neuralized_heston(nn.Module):\n",
    "\tdef __init__(self, device='cpu'):\n",
    "\t\tsuper(neuralized_heston, self).__init__()\n",
    "\t\tself.heston = heston()\n",
    "\t\tself.param_LSTM = param_LSTM(device)\n",
    "\t\tself.device = device\n",
    "\t\tself.to(device)\n",
    "\t\n",
    "\tdef forward(self, params):\n",
    "\t\tparams = self.param_LSTM(params)\n",
    "\t\treturn self.heston(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guidelight-Popvxsqg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
